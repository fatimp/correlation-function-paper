\documentclass[reprint,amsmath,amssymb,aps,pre,showkeys,showpacs,nofootinbib]{revtex4-1}
% Latex
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
% Xelatex
%\usepackage{polyglossia}
%\usepackage{fontspec}
%\setdefaultlanguage{english}
%\setmainfont{DejaVu Sans}
%\setsansfont{DejaVu Sans}
%\setmonofont{DejaVu Sans Mono}
\usepackage{bm}
\usepackage{cleveref}
\usepackage{xcolor}
\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage{subfigure}

\newtheorem{definition}{Definition}

\definecolor{light-gray}{gray}{0.95}
\newcommand{\code}[1]{\colorbox{light-gray}{\texttt{#1}}}
% When cleveref fails to do its job
\newcommand{\apref}[1]{Appendix \ref{#1}}

\begin{document}
\preprint{APS/123-QED}

\author{Aleksei Samarin\textsuperscript{1,2}}
\author{Vasily Postnicov\textsuperscript{1}}
\author{Marina Karsanina\textsuperscript{1}}
\author{Efim Lavrukhin\textsuperscript{1,2}}
\author{Dina Gafurova\textsuperscript{3}}
\author{Aleksey Khlyupin\textsuperscript{1}}
\author{Kirill Gerke\textsuperscript{1}}
\email{kg@ifz.ru}

\affiliation{\textsuperscript{1}Schmidt Institute of Physics of the Earth of
  Russian Academy of Sciences, Moscow, 107031, Russia}
\affiliation{\textsuperscript{2}Computational Mathematics and Cybernetics,
  Lomonosov Moscow State University, Moscow, 119991, Russia}
\affiliation{\textsuperscript{3}Oil and Gas Research Institute Russian Academy
  of Sciences (OGRI RAS) 3, Gubkina st., Moscow, 119333, Russian Federation}

\title{Evaluation of classical correlation functions from 2/3D images on CPU and
  GPU architectures: introducing CorrelationFunctions.jl}

\begin{abstract}
  What have we done?
\end{abstract}

\maketitle

\section{Background and motivation}
\label{sec:background}
Materials are ubiquitous both in nature and in industrial human activities, and
their physical properties are interconnected to
structure\cite{Torquato_book}\cite{Sahimi_book}\cite{Adler_recon}. The information
about the structure usually comes in the way of 2D and 3D images obtained by
microscopy, tomography and other related methodologies. This structural
information can be used for numerous types of analysis, including simulations of
different processes within studied materials or evaluation of their properties
using so-called pore-scale modelling. Unlike computational modelling techniques
a whole class of approximate methods exists including (rigorous) bounds that
allows very fast estimations of physical properties albeit the bounds themselves
are too wide to be applicable in majority of practical problems. Nonetheless, it
is noteworthy that such bounds are originally based on structural descriptors in
the form of correlation functions.

Two ways exist to obtain correlation functions for a given structure at hand:
measure them either experimentally with the help of scattering intensity or
from digital images. None is perfect, as the first approach suffers from the
limitation of CFs that can be obtained this way, while the second one provides
information with limited resolution or/and resolution to field-of-view ratio. In
addition to the resolution conundrum, the most useful imaging methods such as
X-ray computed tomography (XCT) and scanning electron microscopy (SEM) provide
gray-scale images (e.g., X-ray attenuation or electron back-scattering
distributions) due to their underlying physical principles and require labeling
of constituent phases (this is called segmentation) before computation of
CFs. If properly segmented, high-resolution digital images do provide a
possibility to compute any correlation function and, thus, possibility to
address numerous fundamental and practical research problems.

Correlation functions (CFs) as invaluable universal descriptors of structure are
utilized in a multitude of scientific disciplines: material sciences, rock
physics, soil physics and hydrology, cosmology and food engineering, biology and
many others. Computed from 2D and 3D images, CFs can be applied to:
\begin{enumerate}
  \item to characterize the morphology and representativeness via correlation
    lengths;
  \item to perform stochastic reconstructions from experimentally measured CFs
    or 2D to 3D reconstructions based on CFs that can be extracted from less
    dimensions or through penetrable sphere model;
  \item compare different structures to each other, including verification of
    stochastic reconstructions;
  \item compress structural information in the form of raw or parameterized CFs
    with the possibility to recover the structure using stochastic
    reconstruction
  \item describe structural dynamics under different boundary conditions;
  \item extract structural features for deep learning;
  \item fuse multi-scale images and structural information as obtained by
    different methods into a single digital model;
  \item quantify spatial heterogeneity.
\end{enumerate}

Stochastic reconstruction is a separate huge topic, as this approach allows to
solve an inverse problem and recover structure from known set of correlation
functions. This ability for recovery serves as the basis for majority of usages
in the list above. While it is necessary to compute CFs from digital images as a
target set for stochastic reconstructions, they rely more on efficient
recomputations or optimizations, e.g., re-evaluation during simulated
annealing. Such optimizations are not the part of the computational package and
are not considered in this work.

There are different types of correlation functions that in general describe some
probabilities. The main parameter of any correlation function is the number of
points that are utilized to evaluate such a probability. While so-called
$n$-point probability function\cite{Torquato_book} will totally describe any
structure in the limit of $n \rightarrow$ number of voxels/pixels on the image,
computing or storing such a function is not practical. Based on information
content, it was shown that increasing the number of point $n > 2$ only
marginally improves the quality of the structure quantification and these
improvements decay with increasing $n$. For stochastic reconstruction purposes
computation of higher-order statistics will, arguably, not be balanced by
increased number of points, but this is the topic of active research. For
aforementioned reasons, we mainly focus on 2-point statistics, leaving the
possibility to include higher order CFs in the future work. The simplest 2-point
probability function ($S_2$ or autocorrelation) actually arise from small angle
scattering experiments and measures the probability that both ends of line
segment with a given length fall into the same phase. Other types include the
probability of a whole line segment to fall into the phase ($L_2$ function) or
to lie on the interface between phases ($F_{ss}$ function), and mainly originate
from aforementioned bounds on physical properties such as permeability and
elasticity. The general idea of computation of different 2-point CFs is shown in
\cref{fig:functions}. All major details and numerous analytical cases can be
found in seminal work of Torquato \cite{Torquato_book}. To all CFs described in this
book and applicable to digital images we shall refer as to classical correlation
functions.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.9\linewidth]{images/corr.png}
  \caption[]{A schematic depiction of a binary porous media (pores are shown in
    color) with examples of positive events for surface $F_{ss}$, $F_{sv}$ and
    two-point probability $S_2$ correlation functions. The zoomed in area
    represents the difference between the true ``continuous'' interface in
    between pore and solid phases with pixelized ``digital'' interface emerging
    due to limited resolution of digital images.}
  \label{fig:functions}
\end{figure}

While evaluation of correlation functions from 2D and 3D images was a topic of
numerous research papers, the information is highly fragmented, especially in
terms of algorithms and their implementation in the code. Some snippets of code
are available for some functions, but they lack general API and are usually
implemented in proprietary interpreted languages such as Matlab. Due to a recent
leap forward in GPU-based computations, some papers describe computations on
this architecture, but the code is usually not provided. All in all, the
efficient and open-source single API solution utilizing both CPU and GPU
architectures is currently absent.

The aim of this paper is to establish a general open-source solution allowing to
compute all classical correlation functions. This solution should be well
documented with all computational algorithms explained, it should also leverage
on recent advances in programming high-intensity computations and utilize both
CPU and GPU power. Our answer in the form of \code{CorrelationFunctions.jl}
package allows to compute numerous CFs easily on any operating system. The
manuscript describing the package is organized as follows: in \cref{sec:math} we
introduce a reader to the most common and useful correlation functions,
\cref{sec:map} presents all algorithmic details for computing full CFs maps (map
method, full 2-point statistics for a given image). In \cref{sec:scan} we
discuss the second method to calculate correlation functions which is called the
scan approach. In \cref{sec:verification} we verify the all computations based on
known analytical solutions. \cref{sec:efficiency} deals with computational
efficiency of our code, we compare computational times for 2D and 3D images of
different sizes for scanning and map methods as evaluated using either CPU or
GPU. In \cref{sec:examples} some application examples are provided, including
CFs evaluation for multi-phase materials. Finally, \cref{sec:summary} summarizes
all results and outlines possible future improvements.

\section{Introduction to the correlation functions}
\label{sec:math}
In practice porous media are often described with special descriptors called
``correlation functions''. In this section we provide a brief introduction to
these functions which can also be found in \cite{Torquato_book}. The functions
supported by our package are:
\begin{itemize}
\item Lineal-path function $L_2$.
\item Two-point function $S_2$.
\item Cluster function $C_2$.
\item Surface-surface function $F_{ss}$.
\item Surface-void function $F_{sv}$.
\item Pore size function $P$.
\item Chord length function $p$.
\item Phase cross-correlation function $\rho_{ij}$
\end{itemize}

One of basic correlation functions is a lineal path function which is defined as
follows for homogenous media:
\begin{definition}
  Lineal path function $L_2^{(i)}(\bm{r})$ equals to probability that a
  vector $\bm{r}$ lies wholly in phase $i$ when randomly thrown into the
  sample.
\end{definition}
If a sample is isotropic a vector $\bm{r}$ can be replaced with its length
$r$ and the definition becomes:
\begin{definition}
  Lineal path function (for isotropic media) $L_2^{(i)}(r)$ equals to
  probability that a line segment of length $r$ lies wholly in phase $i$ when
  randomly thrown into the sample.
\end{definition}

Another function of big importance is a two-point correlation function $S_2$. A
definition for homogenous media is as follows:
\begin{definition}
  Two point function $S_2^{(i)}(\bm{r})$ equals to probability that both ends
  of a vector $\bm{r}$ lie in phase $i$ when the vector is randomly thrown
  into the sample.
\end{definition}
For isotopic media a vector $\bm{r}$ can be again reduced to a scalar value
$r$ (i.e. a correlation function depends only on length of a vector and not on
its direction.) Mathematically this definition can be expressed with the
following equation:
\begin{equation}
  S_2^{(i)}(\bm{r}) = \langle I^{(i)}(\bm{x}) I^{(i)}(\bm{x} +
  \bm{r}) \rangle
  \label{eq:s2-def}
\end{equation}
where $I^{(i)}$ is an indicator function for a set of all points belonging to
the phase $i$ and $\langle \cdots \rangle$ is an average over all xs.

A function closely related to $S_2$ is phase cross-correlation function
$\rho_{ij}$ which is defined with the following equation:
\begin{equation}
  \rho_{ij}(\bm{r}) = \langle I^{(i)}(\bm{x}) I^{(j)}(\bm{x} +
  \bm{r}) \rangle
  \label{eq:cross-def}
\end{equation}

The next function is a cluster function $C_2$.
\begin{definition}
  Cluster function $C_2^{(i)}(\bm{r})$ equals to probability that both
  ends of a vector $\bm{r}$ lie in the same cluster when the vector is
  randomly thrown into the sample. A cluster is a set of points of the same
  phase $i$ where any to points can be connected by a path lying entirely in
  that phase.
\end{definition}

The next two functions describe surface of a sample. These functions are
surface-surface and surface-void functions. For homogenous media their
definitions are:
\begin{definition}
  Surface-surface function $F_{ss}^{(i)}(\bm{r})$ equals to probability that
  both ends of a vector $\bm{r}$ touch the interface of phase $i$ when the
  vector is randomly thrown into the sample.
\end{definition}
and
\begin{definition}
  Surface-void function $F_{sv}^{(i)}(\bm{r})$ equals to probability that
  one end of a vector $\bm{r}$ touches the interface of phase $i$ and the
  other end touches the void phase when the vector is randomly thrown into the
  sample.
\end{definition}
If we introduce an interface indicator function
\begin{equation*}
  M^{(i)}(\bm{r}) = | \nabla I^{(i)}(\bm{r}) |
\end{equation*}
we can define these functions mathematically as
\begin{align}
  F_{ss}^{(i)}(\bm{r}) &= \langle M^{(i)}(\bm{x}) M^{(i)}(\bm{x} +
  \bm{r}) \rangle \label{eq:fss-def} \\
  F_{sv}^{(i)}(\bm{r}) &= \langle M^{(i)}(\bm{x}) I^{(void)}(\bm{x}
  + \bm{r}) \rangle \label{eq:fsv-def}
\end{align}
As always, there are versions of these functions applicable to scalar argument
for isotropic media.

Pore size function $P(\delta)$ is a probability density function defined as
follows:
\begin{definition}
  $P(\delta)d\delta$ = Probability that a randomly chosen point in a set of points
  belonging to the void phase lies at a distance between $\delta$ and $\delta + d\delta$
  from the nearest point on the pore-solid interface.
\end{definition}

Finally, a chord length function $p^{(i)}(r)$ is defined as follows:
\begin{definition}
$p^{(i)}(r)dz$ = Probability of finding a chord of length between $r$ and $r+dr$
in phase $i$. Chords are all of the line segments between intersections of an
infinitely long line with the two-phase interface.
\end{definition}

\verb+CorrelationFunctions.jl+ is capable to compute all these
functions. Usually there are two implementations for a function. The first
implementation computes a correlation function in specific predefined directions
(i.e. orientation of test vectors thrown into a sample is fixed). There are one
predefined direction in 1D case, four directions in 2D case and thirteen
directions in 3D case. This implementation is somewhat slow but requires much
less memory than the second one. The second implementation computes a
correlation function in all directions and is faster but requires much memory.
These implementations are contained in \code{Directional} and \code{Map} modules
of the package correspondingly.

These functions can work in periodic and non-periodic modes. Periodic mode
assumes that an input sample is periodically continued to the whole Euclidean
space. Non-periodic mode assumes zero-padded input.

\section{The map approach.}
\label{sec:map}
Definition \cref{eq:s2-def} can be rewritten as follows:
\begin{equation}
  S_2^{(i)}(r) = \frac{F^{-1} [|F [A^{(i)}](z)|] (r)}{N(r)} \label{eq:s2-ft}
\end{equation}
where $A^{(i)} \xleftarrow{I^{(i)}} A$ is a binary array obtained by element-wise
application of interface indicator $I^{(i)}$ to an input $A$, $F$ is a discrete
Fourier transform (DFT) operator and $N(r)$ is a total number of trials (vectors
thrown into sample). If we want to calculate $S_2$ function in periodic mode we
need only to apply \cref{eq:s2-ft} to an input to obtain the result because DFT
implicitly continues a signal to infinity \textcolor{red}{Does this need a
clarification?}. In non-periodic mode we need to pad an input with zeros to at
least twice the size minus one for each dimension. In periodic mode a total
number of trials is independent of $r$ and equals to the number of elements in
an input array, or otherwise is calculated as described
\textcolor{red}{Here}. The following algorithm summarizes all said above:
\begin{algorithmic}[1]
  \Procedure{$S_2$}{$A, phase, periodic$}
  \If{$\neg periodic$}
    \State $A \gets zeropad(A)$
  \EndIf
  \State $A^{(phase)} \gets I^{(phase)} (A)$
  \State $\hat{A}^{(phase)} \gets F[A^{(phase)}]$
  \State $\hat{S}_2 \gets |\hat{A}^{(phase)}| / N$
  \State \textbf{return} $F^{-1} [\hat{S}_2]$
  \EndProcedure
\end{algorithmic}
Algorithmic complexity of this implementation if $O(M \log M)$ where $M$ is the
number of elements in the input.

This function is a special case of a cross-correlation function $\rho_{ij}$
which computes a correlation between phases $i$ and $j$ using a formula
\begin{equation}
  \rho_{ij}(r) = \frac{F^{-1} [F[A^{(i)}](z) \overline{F[A^{(j)}](z)}] (r)}{N(r)} \label{eq:cross-ft}
\end{equation}
or an equivalent algorithm
\begin{algorithmic}[1]
  \Procedure{$\rho_{ij}$}{$A, i, j, periodic$}
  \If{$\neg periodic$}
    \State $A \gets zeropad(A)$
  \EndIf
  \State $A^{(i)} \gets I^{(i)} (A)$
  \State $A^{(j)} \gets I^{(j)} (A)$
  \State $\hat{A}^{(i)} \gets F[A^{(i)}]$
  \State $\hat{A}^{(j)} \gets F[A^{(j)}]$
  \State $\hat{\rho} \gets \hat{A}^{(i)} \overline{\hat{A}^{(j)}} / N$
  \State \textbf{return} $F^{-1} [\hat{\rho}]$
  \EndProcedure
\end{algorithmic}

Cluster function can be calculated in the similar manner. Firstly, we apply an
indicator function to an input $A$: $A^{(i)} \xleftarrow{I^{(i)}} A$. When we
label connected components in $A^{(i)}$ using one of many popular algorithms for
this purpose \textcolor{red}{cite something}. This algorithm must take into
account if the function is calculated in periodic mode or not. Then $C_2$
function is a sum of $S_2$ functions calculated for all clusters
separately. Algorithmic complexity of this implementation is $O(MC \log M)$
where $M$ is the number of elements in the input and $C$ is the number of
clusters. The algorithm is as follows:
\begin{algorithmic}[1]
  \Procedure{$C_2$}{$A, phase, periodic$}
  \State $A^{(phase)} \gets I^{(phase)} (A)$
  \State $CC \gets label\_components(A^{(phase)}, periodic)$
  \State $N \gets maximum(CC)$ \Comment Number of connected components
  \State \textbf{return} $\sum\limits_{n=1}^N S_2(CC, n, periodic)$
  \EndProcedure
\end{algorithmic}

For surface-surface and surface-void functions we use an edge detection filter
and then calculate either autocorrelation of the edge or cross-correlation of
the edge and the void phase. The edge is extracted by convolving an input with a
short signal $E$ (\cref{eq:filter-1d} for 1D case, \cref{eq:filter-2d} for 2D case or
\cref{eq:filter-3d-1}-\cref{eq:filter-3d-3} for 3D case).
\begin{align}
  E^{1D} &= \frac{\sqrt{2}}{3} \left[
    \begin{array}{ccc}
        1 & -2 & 1
      \end{array}
    \right] \label{eq:filter-1d} \\
  E^{2D} &= \frac{\sqrt{2}}{9} \left[
    \begin{array}{ccc}
        1 & 1 & 1 \\
        1 & -8 & 1 \\
        1 & 1 & 1
      \end{array}
    \right] \label{eq:filter-2d} \\
  E^{3D}_{ij0} &= \frac{\sqrt{2}}{27} \left[
    \begin{array}{ccc}
        1 & 1 & 1 \\
        1 & 1 & 1 \\
        1 & 1 & 1
    \end{array}
    \right] \label{eq:filter-3d-1} \\
  E^{3D}_{ij1} &= \frac{\sqrt{2}}{27} \left[
    \begin{array}{ccc}
      1 & 1 & 1 \\
      1 & -26 & 1 \\
      1 & 1 & 1
    \end{array}
    \right] \label{eq:filter-3d-2} \\
  E^{3D}_{ij2} &= F^{3D}_{ij0} \label{eq:filter-3d-3}
\end{align}

An algorithm for $F_{ss}$ function is the following:
\begin{algorithmic}[1]
  \Procedure{$F_{ss}$}{$A, phase, periodic$}
  \If{$\neg periodic$}
    \State $A \gets zeropad(A)$
  \EndIf
  \State $A^{(phase)} \gets I^{(phase)} (A)$
  \State $E_A \gets E * A^{(phase)}$
  \State $\hat{E}_A \gets F[E_A]$
  \State $\hat{F}_{ss} \gets |\hat{E}_A| / N$
  \State \textbf{return} $F^{-1} [\hat{F}_{ss}]$
  \EndProcedure
\end{algorithmic}

Using \cref{eq:cross-ft} we obtain an algorithm for surface-void function:
\begin{algorithmic}[1]
  \Procedure{$F_{sv}$}{$A, phase, periodic$}
  \If{$\neg periodic$}
    \State $A \gets zeropad(A)$
  \EndIf
  \State $A^{(phase)} \gets I^{(phase)} (A)$
  \State $A^{(void)} \gets I^{(void)} (A)$
  \State $E_A \gets E * A^{(phase)}$
  \State $\hat{E}_A \gets F[E_A]$
  \State $\hat{A}^{(void)} \gets F[A^{(void)}]$
  \State $\hat{F}_{sv} \gets \hat{E}_A \overline{\hat{A}^{(void)}} / N$
  \State \textbf{return} $F^{-1} [\hat{F}_{sv}]$
  \EndProcedure
\end{algorithmic}

\textcolor{red}{Lineal path function?}

All these algorithms contain parallelizable operations such as fast Fourier
transform, connected components labeling and image filtering, hence they are
perfectly suited for execution on GPUs.

\section{The scan approach.}
\label{sec:scan}
All algorithms described above are executed on the whole input and hence require
a lot of memory. The scan approach deals with memory limitations at the cost of
higher execution time. In this approach we select a list of predefined
directions and cut all one dimensional slices from the input along those
directions. Then for each direction we use an appropriate algorithm in
\cref{sec:map} to calculate a correlation function just for that slice. When all
slices are processed we calculate the result using the formula:
\begin{equation*}
  F^{\bm{d}}(r) = \frac{\sum\limits_i F^{\bm{d}}_i(r) N_i(r)}{\sum\limits_i N_i(r)}
\end{equation*}
Here $F^{\bm{d}}(r)$ is a correlation function computed with respect to a
direction $\bm{d}$, $F^{\bm{d}}_i(r)$ is a ``partial'' correlation
function calculated for a $i$-th slice and $N_i(r)$ is a total number of trials
for a correlation length $r$ and slice $i$.

\textcolor{red}{Lineal path function and chord length function}

Another function which does not use this approach but is in the
\code{Directional} module for historical reasons is the pore size function
$P(r)$. Remember that pore size function is a probability distribution
function. In practice it is better represented as a histogram of pore size
fractions, so all bars of the histogram sum to 1. In our approach we calculate
this histogram using distance transform. For each point $\bm{x}$ distance
transform $\mathcal{D}(\bm{x})$ is defined as
\begin{equation*}
  \mathcal{D}(\bm{x})= \left\{
  \begin{array}{ll}
    0 & \quad \bm{x} \in \text{solid phase} \\
    \min\limits_{y \in \text{solid phase}} \rho(\bm{x},\bm{y}) & \quad \text{otherwise}
  \end{array}
\right.
\end{equation*}
Distance transform has many implementations \textcolor{red}{cite something}. Our
algorithm for calculating $P(r)$ is then:
\begin{algorithmic}[1]
  \Procedure{$P$}{$A, nbins$}
    \State $D \gets \mathcal{D}(A)$ \Comment{Apply $\mathcal{D}$ to each element of $A$}
    \State $D' = \{\forall x \in D: x \ne 0\}$
    \State Bin values in $D'$ to $nbins$ bins to compute a histogram $H$
    \State \textbf{return} $H$
  \EndProcedure
\end{algorithmic}
Algorithmic efficiency is $O(n)$ where $n$ is the number of elements in the
input array.

\section{Verifying our algorithms}
\label{sec:verification}
To verify our package we use random datasets of overlapping disks (the number of
dimensions $n = 2$) or balls ($n = 3$) with radii $R$ and centers placed in
points generated by Poisson point process with a parameter $\lambda$. For these
datasets correlation functions can be given in closed-form expressions for one-,
two- and three-dimensional cases. For the sake of testing we obtain a collection
of disks (resp. balls) in a square (resp. cube) with the side $s$ using the
following algorithm:
\begin{algorithmic}[1]
  \label{testdata}
  \Procedure{testdata}{$s, n, R, \lambda$}
    \State $nballs \gets poisson(\lambda s^n)$ \Comment{$poisson(\lambda)$
      generates random numbers with Poisson distribution with parameter
      $\lambda$.}
    \State Generate $nballs$ random points which are uniformly distributes in
    a cube ($n = 3$) or square ($n = 2$) with a side $s$
    \State Draw balls (disks) of radius $R$ in those points. Store the result in
    an array $output$.
    \State \textbf{return} $output$
  \EndProcedure
\end{algorithmic}

In two-dimensional case we test functions $L_2(r)$, $S_2(r)$, $F_{ss}(r)$ and
$F_{sv}(r)$ using parameters $R = 100$, $\lambda = 4\cdot10^{-5}$ and
$s = 5000$. The correlation functions are calculated in two axial directions
with periodic boundary conditions and the result is averaged across the
directions. Instead of taking one realization of Poisson process we take 15
realizations and average results over them. The result can be seen on
\cref{fig:2d}.

For pore size function $P(r)$ and chord length function $p(\bm{r})$ a slightly
different approach is required. We take a single realization of Poisson point
process with the same parameters $R$ and $\lambda$ in a square with the side
$s = 20000$ (resp. $s = 12000$) and calculate histograms for Pore size
(resp. Chord length) function. Chord length function is calculated in two axial
directions. The theoretical values are integrated over bin ranges and compared
with the number of elements in those bins. The results are presented on
\cref{fig:pscl}.

In three-dimensional case the approach for testing is still the same but with
different parameters to speed up calculations. We choose $R = 20$,
$\lambda = 3\cdot10^{-5}$ and $s = 500$. The correlation functions are
calculated in three axial directions with periodic boundary conditions and the
result is also averaged across the directions as in two-dimensional
case. We take six realizations of Poisson process for averaging the results
which are presented on \cref{fig:3d}.

Pore size and chord length functions are calculated using the side of a cube
$s = 700$. The results are presented on \cref{fig:pscl}.

The results for three-dimensional case are seemingly worse than for
two-dimensional case. This can be explained by a reduced number of realizations
of Poisson process and smaller value of $s$.

\begin{figure*}[t]
  \centering
  \subfigure[Lineal-path correlation function]{
    \includegraphics[width=0.475\linewidth]{images/l2-2d.png}
    \label{fig:l2-2d}}
  \hfill
  \subfigure[Two-point correlation function]{
    \includegraphics[width=0.475\linewidth]{images/s2-2d.png}
    \label{fig:s2-2d}}
  \vskip\baselineskip
  \subfigure[Surface-surface correlation function]{
    \includegraphics[width=0.475\linewidth]{images/ss-2d.png}
    \label{fig:ss-2d}}
  \hfill
  \subfigure[Surface-void correlation function]{
    \includegraphics[width=0.475\linewidth]{images/sv-2d.png}
    \label{fig:sv-2d}}
  \caption[]{A comparison of calculated values of $L_2(r)$, $S_2(r)$,
    $F_{ss}(r)$ and $F_{sv}(r)$ with theoretical values for overlapping disks.}
  \label{fig:2d}
\end{figure*}

\begin{figure*}[t]
  \centering
  \subfigure[Lineal-path correlation function]{
    \includegraphics[width=0.475\linewidth]{images/l2-3d.png}
    \label{fig:l2-3d}}
  \hfill
  \subfigure[Two-point correlation function]{
    \includegraphics[width=0.475\linewidth]{images/s2-3d.png}
    \label{fig:s3-3d}}
  \vskip\baselineskip
  \subfigure[Surface-surface correlation function]{
    \includegraphics[width=0.475\linewidth]{images/ss-3d.png}
    \label{fig:ss-3d}}
  \hfill
  \subfigure[Surface-void correlation function]{
    \includegraphics[width=0.475\linewidth]{images/sv-3d.png}
    \label{fig:sv-3d}}
  \caption[]{A comparison of calculated values of $L_2(r)$, $S_2(r)$,
    $F_{ss}(r)$ and $F_{sv}(r)$ with theoretical values for overlapping balls.}
  \label{fig:3d}
\end{figure*}

\begin{figure*}[t]
  \centering
  \subfigure[Pore size correlation function (2D)]{
    \includegraphics[width=0.475\linewidth]{images/ps-2d.png}
    \label{fig:ps-2d}}
  \hfill
  \subfigure[Chord length correlation function (2D)]{
    \includegraphics[width=0.475\linewidth]{images/cl-2d.png}
    \label{fig:cl-2d}}
  \vskip\baselineskip
  \subfigure[Pore size correlation function (3D)]{
    \includegraphics[width=0.475\linewidth]{images/ps-3d.png}
    \label{fig:ps-3d}}
  \hfill
  \subfigure[Chord length correlation function (3D)]{
    \includegraphics[width=0.475\linewidth]{images/cl-3d.png}
    \label{fig:cl-3d}}
  \caption[]{A comparison of calculated values of $P(r)$ and $p(r)$
    with theoretical values for overlapping disks (\cref{fig:ps-2d} and
    \cref{fig:cl-2d}) and balls(\cref{fig:ps-3d} and \cref{fig:cl-3d}).}
  \label{fig:pscl}
\end{figure*}

\section{Efficiency of our algorithms}
\label{sec:efficiency}
To measure efficiecy of our algorithms we use a machine with the following
configuration:
\begin{itemize}
\item \textbf{CPU}: AMD Ryzen 5 1600X
\item \textbf{Memory}: 32~Gb DDR4-2400 memory
\item \textbf{GPU}: Nvidia Tesla V100 with 32~Gb video memory
\end{itemize}

We generate two (resp. three) dimensional square (resp. cubic) binary arrays
with different number of elements. Each element $a_{ij}$ (resp. $a_{ijk}$) of a
two-dimensional (resp. three-dimensional) array is calculated as follows:
\begin{align*}
  a_{ij} & = \left\{
  \begin{array}{ll}
    0 & \quad vn(5i/s, 5j/s, 0, 5, 34365) < 0.5 \\
    1 & \quad \text{otherwise}
  \end{array}
  \right. \\
  a_{ijk} & = \left\{
  \begin{array}{ll}
    0 & \quad vn(5i/s, 5j/s, 5k/s, 5, 34365) < 0.5 \\
    1 & \quad \text{otherwise}
  \end{array}
  \right.
\end{align*}
Here $vn(x,y,z,o,s)$ is a value noise function. We fix a number of
octaves $o = 5$ and a random seed $s = 34365$. The particular implementation of
value noise for our measurements was taken from \code{ValueNoise.jl} package. An
example of a two-dimensional image generated in this way is on
\cref{fig:valuenoise}.

To measure efficiency of \code{Directional} module we generate ten arrays with
a side of a square $s = 1000, 2000, \dots, 10000$ pixels for two-dimensional
case and ten arrays with a side of a cube $s = 50, 100, \dots, 500$ voxels for
three-dimensional case and calculate execution time for each function. All
functions are calculated with default values of optional arguments (that is:
closed walls boundary conditions and computation along axial directions).

With the \code{Map} module we follow the same procedure. Many functions in
\code{Map} can utilize Nvidia's GPUs using the CUDA library. For example,
two-point correlation function uses FFT transform optimized for Nvidia GPUs and
provided in \code{CUDA.FFT} package. We provide execution times for both CPU and
GPU. The choice between CPU or GPU version is made depending on type of input
array. If it's \code{CuArray} rather than generic \code{AbstractArray} then CUDA
implementation is chosen. Please note, that CPU versions are much slower, so we
choose a different sides of squares ($s = 700, 1350, \dots, 7000$) and cubes
($s = 10, 45, \dots, 350$) for evaluation of the performance.

The measurements of execution time is on \cref{fig:timings}. As you can see, GPU
versions (when available) are faster than CPU versions and limited only by
amount of video memory. Functions in \code{Directional} are slower (with
exception of the lineal-path function) but are also useful in medium
reconstruction algorithms which utilize simulated annealing.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.9\linewidth]{images/timing-image.png}
  \caption[]{An example of 2D image used in timing measurements.}
  \label{fig:valuenoise}
\end{figure}

\begin{figure*}[t]
  \centering
  \subfigure[Two-dimensional case, module \code{Directional}]{
    \includegraphics[width=0.475\linewidth]{images/time-2d.png}
    \label{fig:timings-2d}}
  \hfill
  \subfigure[Three-dimensional case, module \code{Directional}]{
    \includegraphics[width=0.475\linewidth]{images/time-3d.png}
    \label{fig:timings-3d}}
  \vskip\baselineskip
  \subfigure[Two-dimensional case, module \code{Map}, CPU]{
    \includegraphics[width=0.475\linewidth]{images/time-2d-map.png}
    \label{fig:timings-2d-map}}
  \hfill
  \subfigure[Three-dimensional case, module \code{Map}, CPU]{
    \includegraphics[width=0.475\linewidth]{images/time-3d-map.png}
    \label{fig:timings-3d-map}}
  \vskip\baselineskip
  \subfigure[Two-dimensional case, module \code{Map}, GPU]{
    \includegraphics[width=0.475\linewidth]{images/time-2d-gpu.png}
    \label{fig:timings-2d-gpu}}
  \hfill
  \subfigure[Three-dimensional case, module \code{Map}, GPU]{
    \includegraphics[width=0.475\linewidth]{images/time-3d-gpu.png}
    \label{fig:timings-3d-gpu}}
  \caption[]{Execution times for different correlation functions.}
  \label{fig:timings}
\end{figure*}

\section{Examples and applications}
\label{sec:examples}
After the verification of our computational approach based on analytical
solution we can apply our algorithms to evaluate correlation functions for
different porous media images, including real XCT and SEM images.

For demonstration purposes, we computed correlation functions for images of
sandstone found on Digital Rocks Portal \cite{DigitalRocks} all of which have
dimensions $1000 \times 1000 \times 1000$. The result can be seen on
\cref{fig:real-data}.

\begin{figure*}[t]
  \centering
  \subfigure[$S_2^{(void)}$ correlation function.]{
    \includegraphics[width=0.3\linewidth]{real-data-plots/real-s2void.png}
    \label{fig:real-s2}}
  \hfill
  \subfigure[$L_2^{(void)}$ correlation function.]{
    \includegraphics[width=0.3\linewidth]{real-data-plots/real-l2void.png}
    \label{fig:real-l2}}
  \subfigure[$C_2^{(void)}$ correlation function.]{
    \includegraphics[width=0.3\linewidth]{real-data-plots/real-c2void.png}
    \label{fig:real-c2}}
  \vskip\baselineskip
  \subfigure[$F_{ss}$ correlation function.]{
    \includegraphics[width=0.3\linewidth]{real-data-plots/real-ss.png}
    \label{fig:real-ss}}
  \subfigure[$F_{sv}$ correlation function.]{
    \includegraphics[width=0.3\linewidth]{real-data-plots/real-sv.png}
    \label{fig:real-sv}}
  \caption[]{Plots of correlation functions for images of sandstones.}
  \label{fig:real-data}
\end{figure*}

\section{Summary}
\label{sec:summary}
Text

\appendix
\section{Algorithm of computation of lineal-phase function}
\label{linpathalg}
The algorithm below calculates $L_2^{(phase)}$ correlation function for
one-dimensional array $a$. The result is an array of $L_2$ values for
correlation lengths from $0$ to $maxlen-1$. If $periodic$ is true (resp. false)
then periodic (resp. zero padding) boundary conditions are used. The entry point of the
algorithm is the function L2. The efficiency of the proposed algorithm is $O(n)$
where $n$ is the length of the array.

\begin{algorithmic}[1]
  \Procedure{countruns}{$a, len, phase$}
    \State $runslist \gets [\quad]$
    \State $runs \gets 0$
    \ForAll{$x \in a$}
      \If{$x = phase$}
        \State $runs \gets runs + 1$
      \ElsIf{$runs \ne 0$}
        \State $runslist \gets runs:runslist$
        \State $runs \gets 0$
      \EndIf
    \EndFor
    \If{$runs \ne 0$}
      \State $runslist \gets runs:runslist$
    \EndIf
    \State \textbf{return} $runslist$
  \EndProcedure
  \\
  \Procedure{updateruns}{$a, runs, n$}
    \For{$idx = 1,n$}
      \State $a[idx] \gets a[idx] + runs$
      \State $runs \gets runs - 1$
    \EndFor
  \EndProcedure
  \\
  \Procedure{updateperiodic}{$a, first, last, n$}
    \State $sum \gets first + last$
    \State $n \gets \min(n, sum)$
    \For{$idx = 1,n$}
      \State $a \gets \min(idx - 1, first, last, sum - (idx - 1))$
      \State $a[idx] \gets a[idx] + a$
    \EndFor
  \EndProcedure
  \\
  \Procedure{l2}{$a, phase, maxlen, periodic$}
    \State $success \gets zeros(maxlen)$
    \State $total \gets zeros(maxlen)$
    \State $len \gets length(a)$
    \State $nupdates \gets \min(len, maxlen)$
    \State $runs \gets countruns(a, maxlen, phase)$
    \ForAll{$run \in runs$}
      \State $updateruns(success, run, \min(run, maxlen))$
    \EndFor
    \If{$periodic$}
      \State $first \gets first(a)$
      \State $last \gets last(a)$
      \If{$first = last$}
        \State $updateperiodic(success, first, last, nupdates)$
      \EndIf
      \State Increment $total[\text{from} \, 1 \, \text{to} \, nupdates]$ by
      $len$
    \Else
      \State $updateruns(total, len, nupdates)$
    \EndIf
    \State \textbf{return} $success$ divided by $total$ element-wise.  
  \EndProcedure
\end{algorithmic}

\section{Algorithm for image rotation}
\label{rotating}

\begin{algorithmic}[1]
  \Procedure{rotate}{$a, direction, periodic$}
    \ForAll{$slice \in eachslice(a)$}
      \State $shift \gets get\_shift(slice, direction)$
      \State $rotated\_slice \gets circshift(slice, shift)$
      \If{$! periodic$}
        \State $rotated\_slice[end - shift:end] \gets -1$
      \EndIf
    \EndFor
  \State \textbf{return} $rotated$
  \EndProcedure
\end{algorithmic}

\bibliography{apssamp}
\end{document}
