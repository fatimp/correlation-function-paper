\documentclass[reprint,amsmath,amssymb,aps,pre,showkeys,showpacs,nofootinbib]{revtex4-1}
% Latex
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
% Xelatex
%\usepackage{polyglossia}
%\usepackage{fontspec}
%\setdefaultlanguage{english}
%\setmainfont{DejaVu Sans}
%\setsansfont{DejaVu Sans}
%\setmonofont{DejaVu Sans Mono}
\usepackage{bm}
\usepackage{cleveref}
\usepackage{xcolor}
\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage{subfigure}

\newtheorem{definition}{Definition}

\definecolor{light-gray}{gray}{0.95}
\newcommand{\code}[1]{\colorbox{light-gray}{\texttt{#1}}}
% When cleveref fails to do its job
\newcommand{\apref}[1]{Appendix \ref{#1}}

\begin{document}
\preprint{APS/123-QED}

\author{Vasily Postnicov\textsuperscript{1}}
\author{Aleksei Samarin\textsuperscript{1,2}}
\author{Marina Karsanina\textsuperscript{1}}
\author{Aleksey Khlyupin\textsuperscript{1}}
\author{Kirill Gerke\textsuperscript{1}}
\email{kg@ifz.ru}

\affiliation{\textsuperscript{1}Schmidt Institute of Physics of the Earth of
  Russian Academy of Sciences, Moscow, 107031, Russia}
\affiliation{\textsuperscript{2}Computational Mathematics and Cybernetics,
  Lomonosov Moscow State University, Moscow, 119991, Russia}

\title{Evaluation of classical correlation functions from 2/3D images on CPU and
  GPU architectures: introducing CorrelationFunctions.jl}

\begin{abstract}
  What have we done?
\end{abstract}

\maketitle

\section{Background and motivation}
\label{sec:background}
Materials are ubiquitous both in nature and in industrial human activities, and
their physical properties are interconnected to structure
\cite{Torquato_book,Sahimi_book}. The information about the structure usually
comes in the way of 2D and 3D images obtained by microscopy
\cite{moussaoui2018,neumann2019,FIB-SEMpaper}, tomography \cite{xctmat_book} and
other related methodologies.  This structural information can be used for
numerous types of analysis, including simulations of different processes within
studied materials or evaluation of their properties based on 3D structural data
\cite{youssef2005,Miao2017,FDMSS}. Unlike computational modelling techniques a
whole class of approximate methods exists including (rigorous) bounds that
allows very fast estimations of physical properties
\cite{eshelby1957,berryman1986use,rozanski2023} albeit the bounds themselves are
too wide to be applicable in the majority of practical problems. Nonetheless, it
is noteworthy that many of such bounds are originally based on structural
descriptors in the form of correlation functions (CFs).

Two ways exist to obtain correlation functions for a given structure at hand:
measure them either experimentally with the help of scattering intensity
\cite{debye1957scattering,li2018direct} or from digital images
\cite{berryman1985measurement,ma2018SS}. None is perfect, as the first approach
suffers from the limitation of CFs that can be obtained this way, while the
second one provides information with limited resolution or/and resolution to
field-of-view ratio \cite{gerke2015universal}. In addition to the resolution
conundrum, the most useful imaging methods such as X-ray computed tomography
(XCT) and scanning electron microscopy (SEM) provide gray-scale images (e.g.,
X-ray attenuation or electron back-scattering distributions) due to their
underlying physical principles and require labeling of constituent phases (or
segmentation) before computation of CFs \cite{samarin2023robust}. If properly
segmented \cite{NNseg}, high-resolution digital images do provide a possibility
to compute any correlation function and, thus, possibility to address numerous
fundamental and practical research problems.

Correlation functions as invaluable universal descriptors of structure are
utilized in a multitude of scientific disciplines: material sciences
\cite{hasanabadi20163d,Havelka,feng2018reconstruction,chen2022quantifying}, rock
physics \cite{ledesma2018effect}, soil physics and hydrology
\cite{PLoS_ONE,KarsaninaEJSS}, cosmology and food engineering
\cite{TakadaJain,Derossi2019}, biology \cite{veatch2012correlation} and many
others. Computed from 2D and 3D images, CFs can be applied to:
\begin{enumerate}
  \item to characterize the morphology and representativeness via correlation
    lengths \cite{vcapek2009stochastic,thovert2011grain,tensorPRE};
  \item to perform stochastic reconstructions from experimentally measured CFs
    or 2D to 3D reconstructions based on CFs that can be extracted from less
    dimensions or through penetrable sphere model
    \cite{Adler_recon,Y-T,tahmasebiPRL,hasanabadi20163d,karsaninaPRL};
  \item compare different structures to each other, including verification of
    stochastic reconstructions \cite{vcapek2009stochastic,tahmasebiPRL,EPL2};
  \item compress structural information in the form of raw or parameterized CFs
    with the possibility to recover the structure using stochastic
    reconstruction \cite{SciRep1,Havelka,KarsaninaEJSS};
  \item describe structural dynamics under different boundary conditions
    \cite{chen2015dynamic,xu2022correlation,fomin2023soil};
  \item extract structural features for deep learning
    \cite{pilania2017multi,kamrava2020linking,roding2020predicting,KarsaninaEJSS};
  \item fuse multi-scale images and structural information as obtained by
    different methods into a single digital model \cite{Geoderma2018};
  \item quantify spatial heterogeneity \cite{zhang2000pore,REVpaper}.
\end{enumerate}

Stochastic reconstruction is a separate huge topic, as this approach allows to
solve an inverse problem and recover structure from known set of correlation
functions
\cite{Adler_recon,Y-T,vcapek2009stochastic,hasanabadi20163d,Havelka,feng2018reconstruction,tahmasebiPRL,EPL2,thovert2011grain,tensorPRE}. This
ability for recovery serves as the basis for majority of usages in the list
above. While it is necessary to compute CFs from digital images as a target set
for stochastic reconstructions, they rely more on efficient recomputations or
optimizations, e.g., re-evaluation during simulated annealing. Such
optimizations are not the part of the computational package described here and
are not considered in this work.

There are different types of correlation functions that in general describe some
probabilities. The main parameter of any correlation function is the number of
points that are utilized to evaluate such a probability. While so-called
$n$-point probability function \cite{Torquato_book} will completely describe any
structure in the limit of $n \rightarrow$ number of voxels/pixels on the image,
computing or storing such a function is not practical. Based on information
content, it was shown that increasing the number of point $n > 2$ only
marginally improves the quality of the structure quantification and these
improvements decay with increasing $n$ \cite{yao1993high,Gommes2}. For stochastic reconstruction purposes
computation of higher-order statistics will, arguably, not be balanced by
increased number of points, but this is the topic of active research. For
aforementioned reasons, we mainly focus on 2-point statistics, leaving the
possibility to include higher order CFs in the future work. The simplest 2-point
probability function ($S_2$ or autocorrelation) actually arise from small angle
scattering experiments and measures the probability that both ends of line
segment with a given length fall into the same phase. Other types include the
probability of a whole line segment to fall into the phase ($L_2$ function) or
to lie on the interface between phases ($F_{ss}$ function), and mainly originated
from aforementioned bounds on physical properties such as permeability and
elasticity. The general idea of computation of different 2-point CFs is shown in
\cref{fig:functions}. All major details and numerous analytical cases can be
found in seminal work of Torquato \cite{Torquato_book}. To all CFs described in this
book and applicable to digital images we shall refer to as classical correlation
functions.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.9\linewidth]{images/corr.png}
  \caption[]{A schematic depiction of a binary porous media (pores are shown in
    color) with examples of positive events for surface $F_{ss}$, $F_{sv}$ and
    two-point probability $S_2$ correlation functions. The zoomed in area
    represents the difference between the true ``continuous'' interface in
    between pore and solid phases with pixelized ``digital'' interface emerging
    due to limited resolution of digital images.}
  \label{fig:functions}
\end{figure}

While evaluation of correlation functions from 2D and 3D images was a topic of
numerous research papers, the information is highly fragmented, especially in
terms of algorithms and their implementation in the code. Some snippets of code
are available for some functions, but they lack general API and are usually
implemented in proprietary interpreted languages such as Matlab. Due to a recent
leap forward in GPU-based computations, some papers describe computations on
this architecture, but the code is usually not provided. All in all, the
efficient and open-source single API solution utilizing both CPU and GPU
architectures is currently absent.

The aim of this paper is to establish a general open-source solution allowing to
compute all classical correlation functions. This solution should be well
documented with all computational algorithms explained, it should also leverage
on recent advances in programming high-intensity computations and utilize both
CPU and GPU power. Our answer in the form of \code{CorrelationFunctions.jl}
package allows to compute numerous CFs easily on any operating system. The
manuscript describing the package is organized as follows: in \cref{sec:math} we
introduce a reader to the most common and useful correlation functions,
\cref{sec:map} presents all algorithmic details for computing full CFs maps (map
method, full 2-point statistics for a given image). In \cref{sec:scan} we
discuss the second method to calculate correlation functions which is called the
scan approach. In \cref{sec:verification} we verify the all computations based on
known analytical solutions. \cref{sec:efficiency} deals with computational
efficiency of our code, we compare computational times for 2D and 3D images of
different sizes for scanning and map methods as evaluated using either CPU or
GPU. In \cref{sec:examples} some application examples are provided, including
CFs evaluation for multi-phase materials. Finally, \cref{sec:summary} summarizes
all results and outlines possible future improvements.

\section{A brief introduction to correlation functions}
\label{sec:math}
In this section we shall provide major properties of correlation functions
supported by our package; the full list of functions is 
(see \cref{fig:functions} for graphical explanation in addition to definitions below):
\begin{itemize}
\item Two-point probability function $S_2$,
\item Lineal-path function $L_2$,
\item Cluster function $C_2$,
\item Surface-surface function $F_{ss}$,
\item Surface-void function $F_{sv}$,
\item Pore size function $P$,
\item Chord length function $p$,
\item Phase cross-correlation function $\rho_{ij}$.
\end{itemize}
Note that cross-correlation $\rho_{ij}$ is actually not a classical CF, but
technically is a variety of $S_2$ for the case when the end of line segment lie
in different phases. This function is useful for multi-phase structures only, as
for binary media two-point probability CFs are interdependent.

The most widely used is a two-point probability correlation function $S_2$, or
autocorrelation. A definition for homogenous media is as follows:
\begin{definition}
  Two point function $S_2^{(i)}(\bm{r})$ equals to probability that both ends
  of a vector $\bm{r}$ lie in phase $i$ when the vector is randomly thrown
  into the sample.
\end{definition}
For isotopic media a vector $\bm{r}$ can be reduced to a scalar value
$r$ (i.e., a correlation function depends only on length of a vector and not on
its direction). Mathematically this definition can be expressed with the
following equation:
\begin{equation}
  S_2^{(i)}(\bm{r}) = \langle I^{(i)}(\bm{x}) I^{(i)}(\bm{x} +
  \bm{r}) \rangle
  \label{eq:s2-def}
\end{equation}
where $I^{(i)}$ is an indicator function for a set of all points belonging to
the phase $i$ and $\langle \cdots \rangle$ is ensemble average.

A function closely related to $S_2$ is phase cross-correlation function
$\rho_{ij}$ which is defined as follows:
\begin{equation}
  \rho_{ij}(\bm{r}) = \langle I^{(i)}(\bm{x}) I^{(j)}(\bm{x} +
  \bm{r}) \rangle
  \label{eq:cross-def}
\end{equation}

Another basic correlation function is a lineal path function. It provides some
non-trivial information (albeit usually not complete \cite{vcapek2011transport})
about the connectedness of the phase and is defined for homogenous media as:
\begin{definition}
  Lineal path function $L_2^{(i)}(\bm{r})$ equals to probability that a
  vector $\bm{r}$ lies wholly in phase $i$ when randomly thrown into the
  sample.
\end{definition}
If a sample is isotropic a vector $\bm{r}$ can be replaced with its length
$r$ and the definition becomes:
\begin{definition}
  Lineal path function (for isotropic media) $L_2^{(i)}(r)$ equals to
  probability that a line segment of length $r$ lies wholly in phase $i$ when
  randomly thrown into the sample.
\end{definition}

The function that contain a lot of structural connectivity information \cite{JiaoPNAS}
is cluster function $C_2$.
\begin{definition}
  Cluster function $C_2^{(i)}(\bm{r})$ equals to probability that both
  ends of a vector $\bm{r}$ lie in the same cluster when the vector is
  randomly thrown into the sample. A cluster is a set of points of the same
  phase $i$ where any two points can be connected by a path lying entirely in
  that phase.
\end{definition}
Note that for a fully connected phase $C_2$ will be equal to $S_2$, something
we shall utilize later for computations.

The next two functions are called surface-surface ($F_{ss}$) and surface-void
($F_{sv}$) functions and describe an interphase between phases. We skip strict verbal
definitions and first introduce an interface indicator function instead:
\begin{equation*}
  M^{(i)}(\bm{r}) = | \nabla I^{(i)}(\bm{r}) |
\end{equation*}
Here differentiation is understood in the sense of generalized functions,
because an ordinary differential of $I$ is either zero or undefined. For
homogenous media the definitions of surface functions then are:
\begin{align}
  F_{ss}^{(i)}(\bm{r}) &= \langle M^{(i)}(\bm{x}) M^{(i)}(\bm{x} +
  \bm{r}) \rangle \label{eq:fss-def} \\
  F_{sv}^{(i)}(\bm{r}) &= \langle M^{(i)}(\bm{x}) I^{(void)}(\bm{x}
  + \bm{r}) \rangle \label{eq:fsv-def}
\end{align}
These functions are defined for media with dimensionality of 2 and
higher. $F_{sv}$ is a physical quantity inversely proportional to length and
$F_{ss}$ is inversionaly proportional to surface area. Putting it simply,
surface-void function measures length (2D case) or surface (3D case) of a part
of the interface which lies in the void phase of porous medium shifted by vector
$\bm{r}$.  Surface-surface function characterizes intersections of interfaces of
porous medium and its shifted version.  As always, there are versions of these
functions applicable to scalar argument for isotropic media.

Pore size function $P(\delta)$ is a probability density function defined as
follows:
\begin{definition}
  $P(\delta)d\delta$ = Probability that a randomly chosen point in a set of points
  belonging to the void phase lies at a distance between $\delta$ and $\delta + d\delta$
  from the nearest point on the pore-solid interface.
\end{definition}

Finally, a chord length function $p^{(i)}(r)$ is defined as:
\begin{definition}
$p^{(i)}(r)dz$ = Probability of finding a chord of length between $r$ and $r+dr$
in phase $i$. Chord is a line segment which lies entirely in the same phase and
touches the interface with its ends.
\end{definition}

More detailed information on all classical CFs can be found in \cite{Torquato_book}.

\section{Computational methodology}

\code{CorrelationFunctions.jl} is capable to compute all aforementioned
correlation functions. Where possible we provide two implementations for each
CF. The first implementation computes a correlation function in specific
predefined directions (i.e., orientation of test vectors thrown into a sample is
fixed) \cite{jiao2014chawla,EPL1}.  There are one predefined direction in 1D
case, four directions in 2D case (two orthogonal and two diagonal) and thirteen
directions in 3D case (three orthogonal, six diagonal within each orthogonal
plane and four diagonal). The line segment scanning approach is slower for some
CFs but requires much less memory resources. The full map approach establishes
correlations between all points on the image is usually faster.  Both
implementations are contained in \code{Directional} and \code{Map} modules of
the package, correspondingly.

With the help of the package one can compute CFs in periodic and non-periodic
modes.  Periodic mode assumes that an input sample is periodically continued to
the whole Euclidean space. Non-periodic mode assumes zero-padded input.

\subsection{Full correlation map}
\label{sec:map}
Definition \cref{eq:s2-def} can be rewritten as follows:
\begin{equation}
  S_2^{(i)}(r) = \frac{F^{-1} [|F [A^{(i)}](z)|] (r)}{N(r)} \label{eq:s2-ft}
\end{equation}
where $A^{(i)} \xleftarrow{I^{(i)}} A$ is a binary array obtained by element-wise
application of interface indicator $I^{(i)}$ to an input $A$, $F$ is a discrete
Fourier transform (DFT) operator and $N(r)$ is a total number of trials (vectors
thrown into the sample). If we want to calculate $S_2$ function in periodic mode
we need only to apply \cref{eq:s2-ft} to an input to obtain the result. In
non-periodic mode we need to pad an input with zeros to at least twice the size
minus one for each dimension. In periodic mode a total number of trials is
independent of $r$ and equals to the number of elements in an input array. In
non-periodic mode $N(r)$ is calculated as described in
\cref{sec:number-of-trials}. The following algorithm summarizes all the above:
\begin{algorithmic}[1]
  \Procedure{$S_2$}{$A, phase, periodic$}
  \If{$\neg periodic$}
  \State $A \gets zeropad(A)$
  \Comment Pad with at least $2\cdot size(A, i) - 1$ zeros for each dimension $i$.
  \EndIf
  \State $A^{(phase)} \gets I^{(phase)} (A)$
  \State $\hat{A}^{(phase)} \gets F[A^{(phase)}]$
  \State $\hat{S}_2 \gets |\hat{A}^{(phase)}| / N$
  \Comment $N$ is an array with numbers of trials
  \State \textbf{return} $F^{-1} [\hat{S}_2]$
  \EndProcedure
\end{algorithmic}
Algorithmic complexity of this implementation is $O(M \log M)$, where $M$ is the
number of elements in the input image.

Computation of $S_2$ is a special case of a cross-correlation function $\rho_{ij}$
which computes a correlation between phases $i$ and $j$ using a formula:
\begin{equation}
  \rho_{ij}(r) = \frac{F^{-1} [F[A^{(i)}](z) \overline{F[A^{(j)}](z)}] (r)}{N(r)} \label{eq:cross-ft}
\end{equation}
that algorithmically operates as follows:
\begin{algorithmic}[1]
  \Procedure{$\rho_{ij}$}{$A, i, j, periodic$}
  \If{$\neg periodic$}
    \State $A \gets zeropad(A)$
  \EndIf
  \State $A^{(i)} \gets I^{(i)} (A)$
  \State $A^{(j)} \gets I^{(j)} (A)$
  \State $\hat{A}^{(i)} \gets F[A^{(i)}]$
  \State $\hat{A}^{(j)} \gets F[A^{(j)}]$
  \State $\hat{\rho} \gets \hat{A}^{(i)} \overline{\hat{A}^{(j)}} / N$
  \State \textbf{return} $F^{-1} [\hat{\rho}]$
  \EndProcedure
\end{algorithmic}

Cluster function can be calculated with the help of previuously described
procedures.  Firstly, we apply an indicator function to an input $A$: $A^{(i)}
\xleftarrow{I^{(i)}} A$. When we label connected components in $A^{(i)}$ using a
function that is a part of Julia \code{ImageMorphology.jl} library.  Labeling
algorithm must take into account if the function is calculated with periodic
boundary conditions \cite{evstigneev2023}. For periodic boundary conditions we
implemented our own solution as part of the package, as it is absent in the
public domain. Then $C_2$ function is a sum of $S_2$ functions calculated for
all clusters separately. Algorithmic complexity of this implementation is
$O(MC\log M)$ where $M$ is the number of elements in the input and $C$ is the
number of clusters. The algorithm is then written as:
\begin{algorithmic}[1]
  \Procedure{$C_2$}{$A, phase, periodic$}
  \State $A^{(phase)} \gets I^{(phase)} (A)$
  \State $CC \gets label\_components(A^{(phase)}, periodic)$
  \State $N \gets maximum(CC)$ \Comment Number of connected components
  \State \textbf{return} $\sum\limits_{n=1}^N S_2(CC, n, periodic)$
  \EndProcedure
\end{algorithmic}

For surface-surface and surface-void functions we use an edge detection filter
\cite{samarin2023robust} and then calculate either autocorrelation of the edge
or cross-correlation of the edge and the void phase. The edge is extracted by
convolving an input with a short high-pass filter $H$. It has a width $7$ and
all its coefficients with exception of the central coefficient are inversely
proportional to distance from the center:
\begin{equation}
  \begin{aligned}
    H_{ij} &= S \left\{
    \begin{array}{cc}
      \frac{1}{\sqrt{(i-3)^2 + (j-3)^2}} & \quad i \ne 3, j \ne 3 \\
      C & \quad \text{otherwise}
    \end{array}
    \right. \\
    H_{ijk} &= S \left\{
    \begin{array}{cc}
      \frac{1}{\sqrt{(i-3)^2 + (j-3)^2 + (k-3)^3}} & \quad i \ne 3, j \ne 3, k
      \ne 3 \\
      C & \quad \text{otherwise}
    \end{array}
    \right.
  \end{aligned}
  \label{eq:filter-7x7}
\end{equation}
where $C$ is such that all coefficients of $H'$ sum to zero, and $S$ equals to
$30.45849$ in 2D and $172.96232$ in 3D case. The parameters of the filter were adjusted
based on comparison against exact computations of surface functions on smooth-boundary
sets \cite{Postnicov2023}.

An algorithm for $F_{ss}$ function is the following:
\begin{algorithmic}[1]
  \Procedure{$F_{ss}$}{$A, phase, periodic$}
  \If{$\neg periodic$}
    \State $A \gets zeropad(A)$
  \EndIf
  \State $A^{(phase)} \gets I^{(phase)} (A)$
  \State $A_H \gets H * A^{(phase)}$
  \State $\hat{A}_H \gets F[A_H]$
  \State $\hat{F}_{ss} \gets |\hat{A}_H| / N$
  \State \textbf{return} $F^{-1} [\hat{F}_{ss}]$
  \EndProcedure
\end{algorithmic}

Using \cref{eq:cross-ft} we obtain an algorithm for surface-void function:
\begin{algorithmic}[1]
  \Procedure{$F_{sv}$}{$A, phase, periodic$}
  \If{$\neg periodic$}
    \State $A \gets zeropad(A)$
  \EndIf
  \State $A^{(phase)} \gets I^{(phase)} (A)$
  \State $A^{(void)} \gets I^{(void)} (A)$
  \State $A_H \gets H * A^{(phase)}$
  \State $\hat{A}_H \gets F[A_H]$
  \State $\hat{A}^{(void)} \gets F[A^{(void)}]$
  \State $\hat{F}_{sv} \gets \hat{A}_H \overline{\hat{A}^{(void)}} / N$
  \State \textbf{return} $F^{-1} [\hat{F}_{sv}]$
  \EndProcedure
\end{algorithmic}

Our library does not have an implementation for lineal-path maps, although we
know that such implementations exist \cite{Paper}. The reason is a very slow
computation even on GPUs, plus the resulting map is not for all points on the
image, but within a spherical volume (due to rotation of the 3D image during
lineal-path evaluation). Moreover, linear scan approach is orders of magnitude
faster for $L_2$.

All described algorithms contain parallelizable operations such as fast Fourier
transform, connected components labeling and image filtering, hence they are
perfectly suited for execution on GPUs and provide very fast computations (see
wall times below).

\subsection{Directional scanning with line segment}
\label{sec:scan}
All algorithms described above (full correlation maps) are executed on the whole
input and hence require a lot of RAM memory. The scan approach deals with memory
limitations at the cost of higher execution time (except for $L_2$). With
line-segment scanning we select a list of predefined directions and cut all
one-dimensional slices from the input along those directions. Then for each
direction we use an appropriate algorithm in \cref{sec:map} to calculate a
correlation function just for that single slice. When all slices are processed
we calculate the resulting directional or averaged CF using the formula:
\begin{equation*}
  F^{\bm{d}}(r) = \frac{\sum\limits_i F^{\bm{d}}_i(r) N_i(r)}{\sum\limits_i N_i(r)}
\end{equation*}
Here $F^{\bm{d}}(r)$ is a correlation function computed with respect to a
direction $\bm{d}$, $F^{\bm{d}}_i(r)$ is a ``partial'' correlation
function calculated for a $i$-th slice and $N_i(r)$ is a total number of trials
for a correlation length $r$ and slice $i$. Some algorithms require
preprocessing stages before cutting the input in slices, e.g., image filtering
for edge detection or connected components labeling performed on the whole
array, not on slices.

An algorithm for computation of linear-path function for one-dimensional slice
is presented below. Here $a$ is a one-dimensional input array, $phase$ can be
void, solid or some other phase, and $periodic$ is a boolean value which equals
to true if we compute $L_2$ in periodic mode and false otherwise. The efficiency
of the proposed algorithm is $O(n)$ where $n$ is the length of the array.
\begin{algorithmic}[1]
  \Procedure{l2}{$A, phase, periodic$}
    \State $len \gets length(A)$
    \State $result \gets zeros(len)$
    \State $runs \gets countruns(A, phase)$
    \ForAll{$run \in runs$}
      \State $updateruns(result, run)$
    \EndFor
    \If{$periodic$}
      \State $first \gets first(A)$
      \State $last \gets last(A)$
      \If{$first = last$}
        \State $updateperiodic(result, first, last)$
      \EndIf
    \EndIf
    \State \textbf{return} $success$ divided by number of trials
    (see \cref{sec:number-of-trials})
  \EndProcedure
  \\
  \Procedure{countruns}{$A, phase$}
    \State $runslist \gets [\ ]$
    \State $runs \gets 0$
    \ForAll{$x \in A$}
      \If{$x = phase$}
        \State $runs \gets runs + 1$
      \ElsIf{$runs \ne 0$}
        \Comment Add $runs$ to the accumulator
        \State $runslist \gets runs:runslist$
        \State $runs \gets 0$
      \EndIf
    \EndFor
    \If{$runs \ne 0$}
      \State $runslist \gets runs:runslist$
    \EndIf
    \State \textbf{return} $runslist$
  \EndProcedure
  \\
  \Procedure{updateruns}{$A, runs$}
    \State $r \gets runs$
    \For{$idx \gets 0, runs - 1$}
      \State $A[idx] \gets A[idx] + r$
      \State $r \gets r - 1$
    \EndFor
  \EndProcedure
  \\
  \Procedure{updateperiodic}{$A, first, last$}
    \State $sum \gets first + last$
    \For{$idx \gets 0, sum - 1$}
      \State $up \gets \min(idx, first, last, sum - idx)$
      \State $A[idx] \gets A[idx] + up$
    \EndFor
  \EndProcedure
\end{algorithmic}

Cluster function can be calculated using the same technique as in map approach,
but if the number of clusters is high, a naïve $O(n^2)$ algorithm may be more
preferred than $O(MC \log M)$ algorithm. Such an algorithm is present below:
\begin{algorithmic}[1]
  \Procedure{c2}{$A, phase, periodic$}
    \State $A' \gets I^{(phase)}(A)$
    \State $CC \gets label\_components(A', periodic)$
    \State $len \gets length(A)$
    \State $result \gets zeros(len)$
    \ForAll{$slice \in slices(CC)$}
      \For{$i = 0,len-1$}
        \State $end \gets len-1$
        \If{$periodic$}
          \State $end \gets end + i$
        \EndIf
        \For{$j = i, end$}
          \If{$slice[i] = slice[j \mod len] \ne 0$}
            \Comment $0$ is a label for background (phase not equal to $phase$).
            \State $dst \gets |(j \mod len) - i|$
            \State $result[dst] \gets result[dst] + 1$
          \EndIf
        \EndFor
      \EndFor
    \EndFor
    \State \textbf{return} $result$ divided by number of trials
  \EndProcedure
\end{algorithmic}

Before computation of chord length function an input array must be pre-processed
to find an interface for the phase of interest. For this purpose we use
distance transform function defined as follows:
\begin{equation}
  \mathcal{D}(\bm{x})= \left\{
  \begin{array}{ll}
    0 & \quad \bm{x} \in \text{solid phase} \\
    \min\limits_{y \in \text{solid phase}} \rho(\bm{x},\bm{y}) & \quad \text{otherwise}
  \end{array}
\right. \label{eq:distance-transform}
\end{equation}
There are many algorithms for distance transform, including algorithms performed
in linear time \cite{DT}.In \code{chord\_length} function we firstly apply
distance transform to an input to find the interface and then accumulate chord
length in per-slice manner. Finally, chord lengths can be binned in a histogram.
\begin{algorithmic}[1]
  \Procedure{chord\_length}{$A, phase$}
    \State $A' \gets I^{(phase)}(A)$
    \State $A_E \gets \mathcal{D}(A') = 1$
    \Comment We consider elements for which the distance transform equals to $1$
    to be part of the interface
    \State $chord\_list \gets [\ ]$
    \ForAll{$(S', S_E) \in zip(slices(A'), slices(A_E))$}
      \Comment iterate through all one-dimensional slices in $A'$ and
      corresponding slices in $A_E$
      \State $l \gets 0$
      \State $maybe\_chord \gets False$
      \For{$idx \gets 0, length(S')-1$}
        \If{$S_E[idx]$}
          \Comment Interface found
          \If{$l > 1\ and\ maybe\_chord$}
            \Comment Chord found
            \State $chord\_list \gets l:chord\_list$
          \EndIf
          \State $l \gets 0$
          \State $maybe\_chord \gets True$
        \ElsIf{$\neg S'[idx]$}
          \Comment We are not in the phase of interest
          \State $maybe\_chord \gets False$
        \EndIf
      \EndFor
    \EndFor
    \State \textbf{return} $chord\_list$ or $histogram(chord\_list)$
  \EndProcedure
\end{algorithmic}
This implementation also works in linear time.

Another function built on top of distance transform is the pore size function
$P(r)$. Reckon that pore size function is a probability distribution
function. In practice, it is better represented as a histogram of pore sizes
found in the input image. Our algorithm for calculating $P(r)$ is as follows:
\begin{algorithmic}[1]
  \Procedure{$P$}{$A$}
    \State $D \gets \mathcal{D}(A)$
    \Comment Apply $\mathcal{D}$ (\cref{eq:distance-transform}) to each element of $A$
    \State $D' = \{ x \in D: x \ne 0\}$
    \Comment Remove zeros
    \State Bin values in $D'$ to histogram $H$
    \State \textbf{return} $H$
    \Comment Alternatively just return $D'$
  \EndProcedure
\end{algorithmic}
Algorithmic efficiency is $O(n)$ where $n$ is the number of elements in the
input array.

\section{Verification of CFs compuations}
\label{sec:verification}
To verify all algorithms we compare their results against known closed-form
expressions for correlation functions for some particular type of input
data. One such type with analytical solution is overlapping n-balls with fixed
radius and centers generated by Poisson point process. Here we consider both
two-dimensional and three-dimensional cases.

\subsection{Two-dimensional analytical solutions}
Consider an infinite set of disks with radii $R$ and centers generated by
Poisson point process with parameter $\lambda$.

Two-point probability function in this case is \cite{Torquato_book}:
\begin{equation*}
  S_2(r) = e^{-2\lambda \left\{
  \begin{array}{ll}
    \pi R^2 & \quad r > 2R \\
    \pi R^2 + r\sqrt{A}/4 - BR^2 & \quad \text{otherwise}
  \end{array}
  \right.}
\end{equation*}
Here and later $A = 4R^2 - r^2$ and $B = \arccos \frac{r}{2R}$.

An expression for $F_{ss}$ is \cite{samarin2023robust}:
\begin{equation*}
  F_{ss}(r) = 4S_2(r) \left\{
  \begin{array}{ll}
    (\pi\lambda R)^2 & \quad r > 2R \\
    \frac{AR^2\lambda^2 r(B^2 - 2\pi B + \pi^2) + \sqrt{A}R^2\lambda}{Ar} & \quad \text{otherwise}
  \end{array}
  \right.
\end{equation*}

Surface-void function $F_{sv}$ becomes \cite{samarin2023robust}:
\begin{equation*}
  F_{sv}(r) = 2R\lambda S_2(r) \left\{
  \begin{array}{ll}
    \pi & \quad r > 2R \\
    \pi-B & \quad \text{otherwise}
  \end{array}
  \right.
\end{equation*}

Two-point function $L_2$ \cite{Torquato_book}:
\begin{equation*}
  L_2(r) = e^{-\lambda(\pi R^2 + 2rR)}
\end{equation*}

Chord length function $p$ \cite{Torquato_book}:
\begin{equation*}
  p(r) = 2\lambda R e^{-2\lambda rR}
\end{equation*}

And finally pore size function $P$ \cite{Torquato_book}:
\begin{equation*}
  P(r) = 2\lambda\pi (r+R) e^{-\lambda\pi(r^2 + 2rR)}
\end{equation*}

\subsection{Three-dimensional analytical solutions}
As in the previous case, consider an infinite set of balls with radii $R$ and
centers generated by Poisson point process with parameter $\lambda$. Closed-form
expressions for correlations functions are also known for this case for all CFs
\cite{Torquato_book}.

Two-point probability function in this case is:
\begin{equation*}
  S_2(r) = e^{-\lambda\pi \left\{
  \begin{array}{ll}
    \frac{8}{3} R^3 & \quad r > 2R \\
    \frac{4}{3} R^3 + rR^2 - \frac{1}{12}r^3 & \quad \text{otherwise}
  \end{array}
  \right.}
\end{equation*}

Let $\eta = \frac{4}{3}\lambda \pi R^3$. Then an expression for $F_{ss}$ is:
\begin{equation*}
  F_{ss}(r) = S_2(r) \left\{
  \begin{array}{ll}
    \frac{9\eta^2}{R^2} & \quad r > 2R \\
    \frac{9\eta^2}{R^2}(\frac{1}{2}+\frac{r}{4R})^2 + \frac{3\eta}{2rR} & \quad \text{otherwise}
  \end{array}
  \right.
\end{equation*}

Surface-void function $F_{sv}$ is:
\begin{equation*}
  F_{sv}(r) = \frac{3\eta}{R} S_2(r) \left\{
  \begin{array}{ll}
    1 & \quad r > 2R \\
    \frac{1}{2} + \frac{r}{4R} & \quad \text{otherwise}
  \end{array}
  \right.
\end{equation*}

Two-point function $L_2$:
\begin{equation*}
  L_2(r) = e^{-\lambda\pi (\frac{4}{3}R^3 + rR^2)}
\end{equation*}

Chord length function $p$:
\begin{equation*}
  p(r) = \pi\lambda R^2 e^{-\pi\lambda rR^2}
\end{equation*}

And finally pore size function $P$:
\begin{equation*}
  P(r) = 4\pi\lambda(r+R)^2 e^{-\frac{4}{3}\pi\lambda (r^3 + 3r^2R + 3rR^2)}
\end{equation*}

\subsection{Comparison against analytical solutions}
To test out package we generate a realization of random overlapping disks
(\cref{fig:overlapping-disks}) with dimensions $10000 \times 10000$ and
parameters $R = 40\ px$ and $\lambda = 10^{-4}\ px^{-2}$ and compare calculated
correlation functions with their theoretical values.
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.9\linewidth]{images/disks-fragment.png}
  \caption[]{A fragment of overlapping disks used in testing of our library.}
  \label{fig:overlapping-disks}
\end{figure}

For a 3D test, we generate a realization of random overlapping spheres
(\cref{fig:overlapping-disks}) with dimensions $500 \times 500 \times 500$ and
parameters $R = 10\ px$ and $\lambda = 10^{-4}\ px^{-3}$ and compare calculated
correlation functions with their theoretical values. 

The results of comparison of computational results against analytical solutions 
are present on \cref{fig:verification}. It is clear from the test shown that CFs 
are computed with high accuracy; minor deviations are due to finite size of our
Poisson realizations (i.e., larger images reduce deviations \cite{samarin2023robust}).

\begin{figure*}[tp]
  \centering
  \subfigure[Lineal-path correlation function]{
    \includegraphics[width=0.3\linewidth]{images/l2.png}
    \label{fig:l2}}
  \hfill
  \subfigure[Two-point correlation function]{
    \includegraphics[width=0.3\linewidth]{images/s2.png}
    \label{fig:s2}}
  \hfill
  \subfigure[Surface-surface correlation function]{
    \includegraphics[width=0.3\linewidth]{images/ss.png}
    \label{fig:ss}}
  \vskip\baselineskip
  \subfigure[Surface-void correlation function]{
    \includegraphics[width=0.3\linewidth]{images/sv.png}
    \label{fig:sv}}
  \hfill
  \subfigure[Pore size correlation function]{
    \includegraphics[width=0.3\linewidth]{images/ps.png}
    \label{fig:ps}}
  \hfill
  \subfigure[Chord length correlation function]{
    \includegraphics[width=0.3\linewidth]{images/cl.png}
    \label{fig:cl}}
  \caption[]{A comparison of calculated and theoretical values of correlation
    functions for overlapping disks and balls.}
  \label{fig:verification}
\end{figure*}

\section{Applications and benchmarks}
After the verification of our computational approach based on analytical
solution, in this section we apply \code{CorrelationFUnctions.jl} to compute CFs
for a variety of real 2D (SEM) and 3D (XCT) images. We also report benchmark on
execution time and compare GPU and CPU implementations.

\subsection{Examples of application to experimental images}
\label{sec:examples}
A summary which contains information about type of the images, dimensions and resolution
can be found in \cref{tab:samples}. XCT images of sandstones are provided by
Digital Rocks Portal\cite{DigitalRocks}. Correlation functions of XCT images
can be seen on \cref{fig:real-xct}.

\begin{table*}[!pt]
  \centering
  \begin{ruledtabular}
    \begin{tabular}{|c|c|c|c|}
      Sample name & Image type & Dimensions (pixels) & Image resolution ($\mu m$) \\
      \hline
      Castlegate sandstone & XCT & $1000 \times 1000 \times 1000$ & 2.25 \\
      Bentheimer sandstone & XCT & $1000 \times 1000 \times 1000$ & 2.25 \\
      Kirby sandstone      & XCT & $1000 \times 1000 \times 1000$ & 2.25 \\
      Sandstone 1 & SEM &  $1280 \times 869$ & 0.10 \\
      Sandstone 2 & SEM &  $1280 \times 869$ & 0.05 \\
      Carbonate 1 & SEM &  $1024 \times 691$ & 0.06
    \end{tabular}
  \end{ruledtabular}
  \caption{Summary of samples used for calculation of correlation functions.}
  \label{tab:samples}
\end{table*}

\begin{figure*}[pt]
  \centering
  \subfigure[Castlegate sandstone]{
    \includegraphics[width=0.3\linewidth]{samples/CastleGate_2d25um_binary.png}
    \label{fig:castlegate}}
  \hfill
  \subfigure[Bentheimer sandstone]{
    \includegraphics[width=0.3\linewidth]{samples/Bentheimer_2d25um_binary.png}
    \label{fig:bentheimer}}
  \hfill
  \subfigure[Kirby sandstone]{
    \includegraphics[width=0.3\linewidth]{samples/Kirby_2d25um_binary.png}
    \label{fig:kirby}}
  \vskip\baselineskip
  \includegraphics[width=0.3\linewidth]{samples/s2-xct.png}
  \includegraphics[width=0.3\linewidth]{samples/c2-xct.png}
  \includegraphics[width=0.3\linewidth]{samples/l2-xct.png}
  \vskip\baselineskip
  \includegraphics[width=0.3\linewidth]{samples/surf2-xct.png}
  \includegraphics[width=0.3\linewidth]{samples/surfvoid-xct.png}
  \caption[]{Visualization of XCT images and plots of correlation functions for
    these images.}
  \label{fig:real-xct}
\end{figure*}

\subsection{Execution times for our algorithms}
\label{sec:efficiency}
To measure execution times of our algorithms we use a machine with the following
configuration:
\begin{itemize}
\item \textbf{CPU}: AMD Ryzen 7 5800X
\item \textbf{Memory}: 32~Gb DDR4 memory
\item \textbf{GPU}: Nvidia Tesla V100 with 32~Gb video memory
\end{itemize}

We generate two (resp. three) dimensional square (resp. cubic) binary arrays
with different sides. An array used for measurements contains two solid disks
(resp. balls) surrounded by void phase.

To measure efficiency of our code we generate six arrays with a side of a square
$s = 1000, 2000, \dots, 6000$ pixels for two-dimensional case and six arrays
with a side of a cube $s = 50, 100, \dots, 300$ voxels for three-dimensional
case and calculate execution time for each function. All functions are
calculated using periodic boundary conditions. Functions which use per-slice
directional approach are calculated along axial directions.

Functions which calculate full correlation maps are suitable for running on CPU
and GPU, so we provide execution times for both. The cluster function still uses
an algorithm for closest component labeling which works only on CPU, so there is
a potentional for improvement for this function.

The measurements of execution time is on \cref{fig:timings}. As you can see, GPU
versions (when available) are faster than CPU versions and limited only by
amount of video memory. Functions in module \code{Directional} (which utilize
per-slice directional approach) are the slowest among other implementations, but
require less memory.

% Replace by two disks?
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.6\linewidth]{images/timing-image.png}
  \caption[]{One of 2D image used in timing measurements.}
  \label{fig:valuenoise}
\end{figure}

\begin{figure*}[t]
  \centering
  \subfigure[Two-dimensional case, module \code{Directional}]{
    \includegraphics[width=0.475\linewidth]{images/time-2d.png}
    \label{fig:timings-2d}}
  \hfill
  \subfigure[Three-dimensional case, module \code{Directional}]{
    \includegraphics[width=0.475\linewidth]{images/time-3d.png}
    \label{fig:timings-3d}}
  \vskip\baselineskip
  \subfigure[Two-dimensional case, module \code{Map}, CPU]{
    \includegraphics[width=0.475\linewidth]{images/time-2d-map.png}
    \label{fig:timings-2d-map}}
  \hfill
  \subfigure[Three-dimensional case, module \code{Map}, CPU]{
    \includegraphics[width=0.475\linewidth]{images/time-3d-map.png}
    \label{fig:timings-3d-map}}
  \vskip\baselineskip
  \subfigure[Two-dimensional case, module \code{Map}, GPU]{
    \includegraphics[width=0.475\linewidth]{images/time-2d-gpu.png}
    \label{fig:timings-2d-gpu}}
  \hfill
  \subfigure[Three-dimensional case, module \code{Map}, GPU]{
    \includegraphics[width=0.475\linewidth]{images/time-3d-gpu.png}
    \label{fig:timings-3d-gpu}}
  \caption[]{Execution times for different correlation functions.}
  \label{fig:timings}
\end{figure*}

\section{Discussion and outlook}
When to use map and when to use linear scan
  memory
  how fast
  optimization during reconstruction
  +directional CFs for anisotropic media
Reconstructions based on maps - from Cherkasov to SA?
Why we need more functions? Information content
3-point in future - do we need more points?
Or may be we need more CFs? Add topology (Zubov)?
GPU computations are limited by RAM - if we are interested in correlation length of width of cube that can be
put into GPU card memory - we can ensemble by computation in subcubes (possible future upodates)

\section{Summary}
\label{sec:summary}
Text

\appendix
\section{Computation of number of trials for non-periodic mode}
\label{sec:number-of-trials}
Here we assume that an input is padded with zeros to the length $2s_i - 1$
across each dimension $i$ where $s_i$ is the size of the unpadded input in that
dimension. For each dimension we calculate a sequence
\begin{equation*}
  N^i_j = \left\{
  \begin{array}{cc}
    s_i - j & \quad j \in \overline{0, s_i-1} \\
    j - s_i + 1 & \quad j \in \overline{s_i, 2s_i-2}
  \end{array}
  \right.
\end{equation*}

When a number of trials is calculated as follows:
\begin{equation*}
  N_{i_1, i_2, \dots, i_n} = \prod_{k=1}^n N^k_{i_k}
\end{equation*}
Here $n$ is a number of dimensions and $i_k$ is an index into the output array
for $k$-th dimension.

\bibliography{apssamp}
\end{document}
